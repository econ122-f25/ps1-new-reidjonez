---
title: "Problem Set 1"
author: "Reid Jones"
date: "`r Sys.Date()`"
output: github_document
---
install.packages("tidyverse")
install.packages("dplyr")

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
```

### Introduction

This problem set is designed to test your understanding of data wrangling concepts using the **`tidyverse`**, specifically **`dplyr`** and **`tidyr`**, as well as foundational R concepts. You'll primarily work with the `mtcars`, a simulated sales dataset, and new simulated student demographic/grade datasets, applying core verbs and functions to prepare data for analysis. This activity should take approximately 60 minutes.

### Instructions

* Read each task carefully.
* Write your R code in the provided code chunks.
* Run the code to see your output and verify your results.
* `mtcars` is a built-in R dataset (or part of the `tidyverse` installation).

---

## Part 0: R Fundamentals (10 minutes)

This section will test your understanding of basic R syntax, data types, and vector operations.

### Task 0.1: Data Types and Logical Operations

1.  Create a variable `course_name` and assign it the string `"Introduction to Data Science"`.
2.  Create a variable `num_students` and assign it the integer value `45`.
3.  Check the data type (`class()`) of `course_name` and `num_students`.
4.  Create a numeric variable `pi_value` with the value $3.14159$.
5.  Create a logical variable `is_active` and set it to `TRUE`.
6.  Evaluate the following logical expressions and print their results:
    * Is `num_students` greater than or equal to `50`?
    * Is `course_name` exactly equal to `"introduction to data science"` (case-sensitive)?

```{r}
# 1. Create a variable course_name
course_name <- "Introduction to Data Science"

# 2. Create a variable num_students
num_students <- 45

# 3. Check the data type of both variables
class(course_name)
class(num_students)

# 4. Create a numeric variable pi_value
pi_value <- 3.14159

# 5. Create a logical variable is_active
is_active <- TRUE

# 6. Evaluate logical expressions
num_students >= 50
course_name == "introduction to data science"
```

---

### Task 0.2: Working with Vectors

1.  Create a numeric vector named `temperatures` with the values $22, 25, 19, 28, 23$.
2.  Calculate the `sum()` and `mean()` of the `temperatures` vector.
3.  Add a new temperature, $30$, to the `temperatures` vector (re-assign the variable).
4.  Create a new logical vector named `is_hot` that is `TRUE` for temperatures greater than $25$ and `FALSE` otherwise.

```{r}
# 1. Create a numeric vector temperatures
temperatures<- c(22, 25, 19, 28, 23)

# 2. Calculate sum and mean
sum(temperatures)
mean(temperatures)

# 3. Add a new temperature 30 and re-assign
temperatures <- c(temperatures, 30)

# 4. Create a logical vector is_hot (TRUE if > 25)
is_hot <- temperatures > 25

# Print results to check
temperatures
is_hot
```

---

## Part 1: `dplyr` Fundamentals with `mtcars` (25 minutes)

This section focuses on applying core `dplyr` verbs to the classic `mtcars` dataset. The `mtcars` dataset contains information about various car models from 1973-74.

### Task 1.1: Filtering and Arranging

1.  The `mtcars` dataset has been pre-processed for you to include `car_model` as a column.
2.  Filter the dataset to include only cars with `cyl` (number of cylinders) equal to `4` or `6` AND `mpg` (miles per gallon) greater than `20`.
3.  Arrange the results first by `mpg` in ascending order, and then by `cyl` in descending order.


```{r}
# Pre-processing step: Convert rownames to car_model
mtcars_processed <- mtcars %>%
  rownames_to_column("car_model")

# 2. Filter for cyl = 4 or 6 AND mpg > 20
# 3. Arrange by mpg ascending, then cyl descending
filtered_cars <- mtcars_processed %>%
  filter((cyl == 4 | cyl == 6) & mpg > 20) %>%
  arrange(mpg, desc(cyl))

# Print the result
filtered_cars
```

### Short Answer
Based on your filtered and arranged results, briefly describe the characteristics of the cars that appear at the top of your output. What does this tell you about the relationship between cylinders and miles per gallon in this subset?

### Answer
The cars at the top of the results are mostly 6-cylinder models right at the cutoff of 21 mpg, followed closely by 4-cylinder models with slightly higher mpg, showing that within this subset, 4-cylinder cars tend to achieve better fuel efficiency than 6-cylinder ones.

---

### Task 1.2: Mutating and Selecting

Using the `mtcars_processed` dataset:

1.  Create a new column `hp_per_wt` by dividing `hp` (horsepower) by `wt` (weight in 1000 lbs).
2.  Create another new column `qsec_category` based on `qsec` (1/4 mile time):
    * `"Fast"` if `qsec < 17`
    * `"Medium"` if `qsec >= 17` and `qsec < 19`
    * `"Slow"` if `qsec >= 19`
3.  Select only the `car_model`, `mpg`, `hp`, `wt`, `hp_per_wt`, and `qsec_category` columns.

```{r}
# Pre-processing step: Convert rownames to car_model
mtcars_processed <- mtcars %>%
  rownames_to_column("car_model")

# 1. Create new column hp_per_wt
# 2. Create new column qsec_category
# 3. Select requested columns
mtcars_with_new <- mtcars_processed %>%
  mutate(
    hp_per_wt = hp / wt,
    qsec_category = case_when(
      qsec < 17 ~ "Fast",
      qsec >= 17 & qsec < 19 ~ "Medium",
      qsec >= 19 ~ "Slow"
    )
  ) %>%
  select(car_model, mpg, hp, wt, hp_per_wt, qsec_category)

# View result
mtcars_with_new
```

### Short Answer
Why might creating `hp_per_wt` and `qsec_category` be useful metrics when analyzing car performance, beyond just raw horsepower and weight?

### Answer 
Creating hp_per_wt helps compare how efficiently cars turn power into performance relative to their size, while qsec_category groups cars into clear performance tiers, making it easier to see patterns than with raw horsepower or weight alone.

---

### Task 1.3: Grouped Summaries

Using the `mtcars_processed` dataset:

1.  Group the data by `cyl` (number of cylinders) and `am` (transmission type: 0 for automatic, 1 for manual).
2.  For each group, calculate the **average `mpg`**, the **median `hp`**, and the **number of cars** (`n()`).
3.  Arrange the final result first by `cyl` (ascending) and then by `average_mpg` (descending).

```{r}
# Pre-processing step: Convert rownames to car_model
mtcars_processed <- mtcars %>%
  rownames_to_column("car_model")

# 1. Group by cyl and am
# 2. Summarize average mpg, median hp, and number of cars
# 3. Arrange by cyl ascending, then average mpg descending
grouped_summary <- mtcars_processed %>%
  group_by(cyl, am) %>%
  summarise(
    average_mpg = mean(mpg),
    median_hp = median(hp),
    num_cars = n(),
    .groups = "drop"
  ) %>%
  arrange(cyl, desc(average_mpg))

# View result
grouped_summary

```

### Short Answer
Based on your grouped summary, what general trends do you observe regarding average `mpg` and median `hp` across different combinations of `cylinders` and `transmission` types? How do these summaries help differentiate car characteristics?

### Answer
Cars with fewer cylinders, especially 4-cylinder manuals, have much higher mpg but lower horsepower, while 8-cylinder cars show the opposite pattern with very high horsepower but poor mpg, and these summaries highlight how engine size and transmission type together shape efficiency versus power.

---

## Part 2: Reshaping and Joining Data (25 minutes)

For this part, we'll explore reshaping and joining using a simulated sales dataset and new simulated student enrollment data.

**Run this code chunk first to set up the data:**

```{r, echo = TRUE}
# Part 2 Data Setup
product_sales_wide <- tibble(
  product = c("Laptop", "Monitor", "Keyboard"),
  `2020` = c(1000, 500, 800),
  `2021` = c(1100, 550, 850),
  `2022` = c(1250, 600, 900)
) %>%
  rename(Year_2020 = `2020`, Year_2021 = `2021`, Year_2022 = `2022`) # Rename to avoid issues with non-syntactic names

# Simulated Student and Grade Data
students_demographics <- tibble(
  student_id = c("S001", "S002", "S003", "S004", "S005", "S007"), # S007 is a new student, no grades yet
  student_name = c("Alice", "Bob", "Charlie", "David", "Eve", "Frank"),
  major = c("CS", "Math", "Physics", "CS", "Biology", "History"),
  enrollment_year = c(2020, 2021, 2020, 2022, 2021, 2023)
)

student_grades <- tibble(
  student_id = c("S001", "S002", "S003", "S001", "S006", "S004"), # S006 has grades but no demographic info
  course_id = c("CS101", "MA201", "PH301", "CS102", "BI101", "CS205"),
  semester = c("Fall 2020", "Spring 2022", "Fall 2021", "Spring 2021", "Fall 2021", "Spring 2023"),
  grade_score = c(92, 85, 88, 78, 75, 90) # Assuming numeric scores for easier calculation
)

# Display the dataframes
print(product_sales_wide)
print(students_demographics)
print(student_grades)
```

---

### Task 2.1: New Variable Creation: Wide vs. Long (`product_sales` dataset)

This task demonstrates how creating new variables that depend on previous time periods is much easier in a long (tidy) format.

1.  **Analysis in Wide Format:** Using the `product_sales_wide` dataset, create new columns for the **year-over-year growth rate** for 2021 and 2022.
    * `Growth_2021`: `(Year_2021 - Year_2020) / Year_2020 * 100`
    * `Growth_2022`: `(Year_2022 - Year_2021) / Year_2021 * 100`

```{r}
# Calculate year-over-year growth
product_sales_growth <- product_sales_wide %>%
  mutate(
    Growth_2021 = (Year_2021 - Year_2020) / Year_2020 * 100,
    Growth_2022 = (Year_2022 - Year_2021) / Year_2021 * 100
  )
# Display results
print(product_sales_growth)
```

2.  **Reshape to Long Format:** Reshape `product_sales_wide` into a long format called `product_sales_long`. Pivot the year columns (`Year_2020`, `Year_2021`, `Year_2022`) into two new columns: `Year` and `Sales`. Make sure `Year` is numeric.

```{r}
product_sales_long <- product_sales_wide %>%
  pivot_longer(
    cols = starts_with("Year_"),
    names_to = "Year",
    values_to = "Sales",
    names_prefix = "Year_",
    names_transform = list(Year = as.integer)
  )

print(product_sales_long)
```
3.  **Analysis in Long Format:** Using the `product_sales_long` dataset, calculate a single `Growth_Rate` column that represents the year-over-year growth for each product. You should use `group_by()` and `lag()`. The formula for growth rate is `(current_year_sales - previous_year_sales) / previous_year_sales * 100`.

```{r}
product_sales_growth_long <- product_sales_long %>%
  group_by(product) %>%
  arrange(Year, .by_group = TRUE) %>%
  mutate(
    Growth_Rate = (Sales - lag(Sales)) / lag(Sales) * 100
  )

print(product_sales_growth_long)
```

### Short Answer
Compare the code required to calculate the year-over-year growth rate in the wide format versus the long format. Which approach is more concise and scalable if you had many more years of data? Why is the long format generally preferred for this type of time-series calculation?

### Answer
In wide format you have to manually write a new formula for each pair of years, which quickly becomes repetitive and unscalable as more years are added. In long format a single grouped mutate with lag() handles all years automatically, making it more concise, flexible, and generally preferred for time-series analysis.

---

### Task 2.2: Mutating Joins: Student Demographics and Grades

This task explores combining student demographic information with their academic performance. Pay close attention to how different join types handle students who may or may not have corresponding grade records.

1.  **Inner Join:** Perform an `inner_join()` to combine `students_demographics` with `student_grades` based on `student_id`. This will show students who have **both** demographic information and at least one grade record.
2.  **Left Join:** Perform a `left_join()` to combine `students_demographics` (left table) with `student_grades` based on `student_id`. This will keep **all students** from the demographic data and add their grade records where available.
3.  **Advanced Mutate (after Left Join):** After performing the left join, calculate the **average `grade_score` for each student**. This will require grouping by `student_id` and `student_name`.

```{r}
# Inner join: only students who have demographics and at least one grade
inner_result <- inner_join(students_demographics, student_grades, by = "student_id")
inner_result
# Explanation: Keeps only rows where student_id exists in both datasets.
# Students like S001, S002, S003, S004 will appear.
# Students with only demographics (S007) or only grades (S006) will be excluded.

# Left join: keep all students from demographics, add grades when available
left_result <- left_join(students_demographics, student_grades, by = "student_id")
left_result
# Explanation: All demographic records remain in the output.
# Students without grades (like S007) will have NA in grade columns.
# Students with grades but no demographics (like S006) are not included.

# Advanced mutate after left join: average grade per student
left_avg <- left_result %>%
  group_by(student_id, student_name) %>%
  mutate(avg_grade_score = mean(grade_score, na.rm = TRUE))

left_avg
# Explanation: Adds a new column avg_grade_score showing each student’s average grade.
# Students without grades (NA) will have NA in their average score.

```

### Short Answer
Compare the number of rows and the content of the `inner_join()` and `left_join()` results. Specifically, identify which student(s) are present in one join but not the other, and explain why. What does the average grade calculation reveal about students with multiple grades or no grades?

### Answer
The inner join returns S001, S002, S003, and S004 only, since those IDs appear in both tables. The left join also includes S005 Eve and S007 Frank with grade fields as NA, while S006 appears in grades only and is absent from both the inner join and the left-side demographics. The average grade shows that students with multiple grades, like S001, get a mean across their scores, students with one grade keep that value, and students with no grades have NA for the average.

---

### Task 2.3: Filtering Joins: Identifying Student Enrollment Status

This task focuses on using filtering joins to identify different categories of students based on their enrollment and grade records.

1.  **Enrolled Students:** Use a `semi_join()` to identify which students from `students_demographics` are actually enrolled in and have a grade record in `student_grades`. This should return only columns from `students_demographics`.
2.  **Students Without Grades:** Use an `anti_join()` to identify which students from `students_demographics` are in the system but currently do *not* have any grade records in `student_grades` (e.g., new students, or those who haven't completed courses yet). This should return only columns from `students_demographics`.
3.  **Grades Without Students:** Use an `anti_join()` to identify any grade records in `student_grades` that do *not* correspond to an existing student in `students_demographics` (e.g., a data entry error or a record for a past student no longer in the demographic system). This should return only columns from `student_grades`.

```{r}
# Enrolled students: in demographics and have at least one grade
enrolled_students <- semi_join(students_demographics, student_grades, by = "student_id")
enrolled_students
# Expected IDs: S001 S002 S003 S004

# Students without grades: in demographics but no grade records
students_without_grades <- anti_join(students_demographics, student_grades, by = "student_id")
students_without_grades
# Expected IDs: S005 S007

# Grades without students: grade rows with no matching student in demographics
grades_without_students <- anti_join(student_grades, students_demographics, by = "student_id")
grades_without_students
# Expected ID present only in grades: S006
```

### Short Answer
Describe the distinct insights gained from each of the three filtering joins in this task. How do these joins help in data validation and understanding the completeness of your student records?

### Answer
The semi join shows which students are actively enrolled and have grades which confirms who is fully represented in both datasets. The anti join on demographics shows students in the system without grades which points to new students or missing records. The anti join on grades flags grade entries with no matching student which helps catch errors. Together these checks give a quick way to validate data quality and spot gaps.



